{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BART(Vanilla + Gigaword)-CNN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOpJbuUbFngsN6mmzfPO62p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10BPF1DyIgyS","executionInfo":{"status":"ok","timestamp":1624946068512,"user_tz":-480,"elapsed":497,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"1eaed7ea-f549-4a99-a66c-76f1703e0835"},"source":["gpu_info_examine = !nvidia-smi\n","gpu_info_examine = '\\n'.join(gpu_info_examine)\n","if gpu_info_examine.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info_examine)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Jun 29 05:54:27 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   51C    P0    41W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Kky8CaTJZGD","executionInfo":{"status":"ok","timestamp":1624946068918,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"4fbeaf1d-2ff4-4f87-ccdb-c9a718db4f01"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Z79FsrpKDIJ","executionInfo":{"status":"ok","timestamp":1624946087393,"user_tz":-480,"elapsed":18481,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"1cf0cc59-aaf4-40c1-cc91-06177efd0809"},"source":["!pip install transformers\n","!pip install datasets\n","!pip install torch\n","!pip install tqdm\n","!pip install numpy"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.8.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.6.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.5.0)\n","Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"10dG_tO_IN5u","executionInfo":{"status":"ok","timestamp":1624946088649,"user_tz":-480,"elapsed":1271,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}}},"source":["from transformers import AutoTokenizer, AutoModel, BartForConditionalGeneration, BartTokenizerFast\n","from datasets import load_dataset\n","import torch as torch\n","from tqdm import tqdm\n","from datasets import load_metric\n","import numpy as np"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"67EwXdPlOfOn","executionInfo":{"status":"ok","timestamp":1624946088650,"user_tz":-480,"elapsed":8,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"b73955bc-89ce-44e6-d4b9-fb8d0fe224f1"},"source":["torch.cuda.empty_cache()\n","torch.cuda.memory_summary(device=None, abbreviated=False)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Vq7w312Ic-2","executionInfo":{"status":"ok","timestamp":1624946096763,"user_tz":-480,"elapsed":8119,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"f1f71ef4-f51d-4c1e-de59-73f99c473024"},"source":["model_checkpoint = 'facebook/bart-large-cnn' #'facebook/bart-base' #'a1noack/bart-large-gigaword'\n","tokenizer = BartTokenizerFast.from_pretrained(model_checkpoint)\n","model = BartForConditionalGeneration.from_pretrained(model_checkpoint, return_dict=True)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"uLkvuq5iPUqu","executionInfo":{"status":"ok","timestamp":1624946096763,"user_tz":-480,"elapsed":25,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"f482ebbf-acc2-48ec-ec24-e6094e0a8fb6"},"source":["torch.cuda.memory_summary(device=None, abbreviated=False)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BfVX8_OMJ3wF","executionInfo":{"status":"ok","timestamp":1624946096764,"user_tz":-480,"elapsed":23,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"e6681506-c0fc-4750-dea7-2a2671d54bc6"},"source":["test = load_dataset(\"cnn_dailymail\", '3.0.0',split='test[15:20]')\n","# test = load_dataset(\"cnn_dailymail\", '3.0.0',split='test[10:15]')\n","# test = load_dataset(\"cnn_dailymail\", '3.0.0',split='test[5:10]')\n","# test = load_dataset(\"cnn_dailymail\", '3.0.0',split='test[0:5]')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Reusing dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAyGxfDcO74f","executionInfo":{"status":"ok","timestamp":1624946096764,"user_tz":-480,"elapsed":19,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"684daff8-d6e5-4276-9d51-6538966dde48"},"source":["print(test)\n","print(model.config.max_length)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Dataset({\n","    features: ['article', 'highlights', 'id'],\n","    num_rows: 5\n","})\n","142\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"uzzsJyOIO50G","executionInfo":{"status":"ok","timestamp":1624946097174,"user_tz":-480,"elapsed":427,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"f272f2ae-1307-40a6-ae0c-c63c0d83904f"},"source":["torch.cuda.memory_summary(device=None, abbreviated=False)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"FlN8ckklLW1n","executionInfo":{"status":"ok","timestamp":1624946099992,"user_tz":-480,"elapsed":2822,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}}},"source":["encodings =  tokenizer(test['article'], return_tensors='pt', padding=True, truncation=True, max_length=1024).to(device)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jBbXzI7MHH2","executionInfo":{"status":"ok","timestamp":1624946099994,"user_tz":-480,"elapsed":14,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"fde8776c-55eb-4ad1-8b22-50fb0a14b46a"},"source":["print(encodings['input_ids'].shape)\n","print(encodings['attention_mask'].shape)\n","encodings"],"execution_count":12,"outputs":[{"output_type":"stream","text":["torch.Size([5, 1024])\n","torch.Size([5, 1024])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[    0,   530,  2681,  ...,    11,    63,     2],\n","        [    0,  1640, 16256,  ...,     1,     1,     1],\n","        [    0,  1640, 16256,  ...,  9095,     6,     2],\n","        [    0, 32826,    36,  ...,     1,     1,     1],\n","        [    0, 33193, 19927,  ...,  1699,     6,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0')}"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"nvu2bONLN5tU","executionInfo":{"status":"ok","timestamp":1624946099995,"user_tz":-480,"elapsed":13,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}}},"source":["# encodings['input_ids'][:5].shape\n","# encodings['input_ids'][10:].shape"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_EPUrgaJ5fa","executionInfo":{"status":"ok","timestamp":1624946100947,"user_tz":-480,"elapsed":964,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}}},"source":["model = model.to(device)\n","model.eval()\n","number_beams = 8"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hfITbbQqNbae","executionInfo":{"status":"ok","timestamp":1624946104882,"user_tz":-480,"elapsed":3937,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"d00949d3-5f9d-42d5-98a9-435be39369d8"},"source":["with torch.no_grad():\n","      result1 = model.generate(encodings['input_ids'],  num_beams=number_beams, return_dict_in_generate=True, max_length=model.config.max_length, output_scores=True, output_attentions=True)\n","    # result = model.generate(encodings['input_ids'],  num_beams=number_beams, return_dict_in_generate=True, max_length=model.config.max_length, output_scores=True, output_attentions=True)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H7hBLDjdKRnT","executionInfo":{"status":"ok","timestamp":1624946104883,"user_tz":-480,"elapsed":19,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"95a8bdfa-9b04-41e8-f033-1716023f0e47"},"source":["all = []\n","log_sent = []\n","print(result1.sequences.shape)\n","print(\"CNN Dailymail vocab size: \", result1.scores[0].shape[1])\n","print(\"Input ids size\", encodings['input_ids'].shape)\n","for batch_num in range(0, result1.scores[0].shape[0], number_beams):\n","    # lls = torch.tensor(0, dtype=torch.float)\n","    # print(batch_num)\n","    max_score = torch.tensor(-1*1e6, dtype=torch.float).to(device)\n","    for beam_num in range(number_beams):\n","        print([torch.max(result1.scores[-1][batch_num+beam_num]), max_score])\n","        max_score = torch.max(torch.stack([torch.max(result1.scores[-1][batch_num+beam_num]), max_score]))\n","    log_sent.append(max_score)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["torch.Size([5, 65])\n","CNN Dailymail vocab size:  50264\n","Input ids size torch.Size([5, 1024])\n","[tensor(-0.8043, device='cuda:0'), tensor(-1000000., device='cuda:0')]\n","[tensor(-0.8043, device='cuda:0'), tensor(-0.8043, device='cuda:0')]\n","[tensor(-0.8043, device='cuda:0'), tensor(-0.8043, device='cuda:0')]\n","[tensor(-0.8043, device='cuda:0'), tensor(-0.8043, device='cuda:0')]\n","[tensor(-0.8043, device='cuda:0'), tensor(-0.8043, device='cuda:0')]\n","[tensor(-0.8043, device='cuda:0'), tensor(-0.8043, device='cuda:0')]\n","[tensor(-0.8043, device='cuda:0'), tensor(-0.8043, device='cuda:0')]\n","[tensor(-0.8043, device='cuda:0'), tensor(-0.8043, device='cuda:0')]\n","[tensor(-34.9259, device='cuda:0'), tensor(-1000000., device='cuda:0')]\n","[tensor(-36.4917, device='cuda:0'), tensor(-34.9259, device='cuda:0')]\n","[tensor(-36.7551, device='cuda:0'), tensor(-34.9259, device='cuda:0')]\n","[tensor(-36.4029, device='cuda:0'), tensor(-34.9259, device='cuda:0')]\n","[tensor(-38.9479, device='cuda:0'), tensor(-34.9259, device='cuda:0')]\n","[tensor(-38.4490, device='cuda:0'), tensor(-34.9259, device='cuda:0')]\n","[tensor(-38.0902, device='cuda:0'), tensor(-34.9259, device='cuda:0')]\n","[tensor(-39.0384, device='cuda:0'), tensor(-34.9259, device='cuda:0')]\n","[tensor(-0.6400, device='cuda:0'), tensor(-1000000., device='cuda:0')]\n","[tensor(-0.6400, device='cuda:0'), tensor(-0.6400, device='cuda:0')]\n","[tensor(-0.6400, device='cuda:0'), tensor(-0.6400, device='cuda:0')]\n","[tensor(-0.6400, device='cuda:0'), tensor(-0.6400, device='cuda:0')]\n","[tensor(-0.6400, device='cuda:0'), tensor(-0.6400, device='cuda:0')]\n","[tensor(-0.6400, device='cuda:0'), tensor(-0.6400, device='cuda:0')]\n","[tensor(-0.6400, device='cuda:0'), tensor(-0.6400, device='cuda:0')]\n","[tensor(-0.6400, device='cuda:0'), tensor(-0.6400, device='cuda:0')]\n","[tensor(-0.5767, device='cuda:0'), tensor(-1000000., device='cuda:0')]\n","[tensor(-0.5767, device='cuda:0'), tensor(-0.5767, device='cuda:0')]\n","[tensor(-0.5767, device='cuda:0'), tensor(-0.5767, device='cuda:0')]\n","[tensor(-0.5767, device='cuda:0'), tensor(-0.5767, device='cuda:0')]\n","[tensor(-0.5767, device='cuda:0'), tensor(-0.5767, device='cuda:0')]\n","[tensor(-0.5767, device='cuda:0'), tensor(-0.5767, device='cuda:0')]\n","[tensor(-0.5767, device='cuda:0'), tensor(-0.5767, device='cuda:0')]\n","[tensor(-0.5767, device='cuda:0'), tensor(-0.5767, device='cuda:0')]\n","[tensor(-0.5996, device='cuda:0'), tensor(-1000000., device='cuda:0')]\n","[tensor(-0.5996, device='cuda:0'), tensor(-0.5996, device='cuda:0')]\n","[tensor(-0.5996, device='cuda:0'), tensor(-0.5996, device='cuda:0')]\n","[tensor(-0.5996, device='cuda:0'), tensor(-0.5996, device='cuda:0')]\n","[tensor(-0.5996, device='cuda:0'), tensor(-0.5996, device='cuda:0')]\n","[tensor(-0.5996, device='cuda:0'), tensor(-0.5996, device='cuda:0')]\n","[tensor(-0.5996, device='cuda:0'), tensor(-0.5996, device='cuda:0')]\n","[tensor(-0.5996, device='cuda:0'), tensor(-0.5996, device='cuda:0')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCpVGhegKSpc","executionInfo":{"status":"ok","timestamp":1624946104884,"user_tz":-480,"elapsed":17,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"69650646-43f8-48e2-9237-68d1ff910266"},"source":["print(log_sent)\n","print(torch.stack(log_sent).sum())\n","print(torch.exp((-1*(torch.stack(log_sent).sum()))/result1.sequences.shape[1]))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[tensor(-0.8043, device='cuda:0'), tensor(-34.9259, device='cuda:0'), tensor(-0.6400, device='cuda:0'), tensor(-0.5767, device='cuda:0'), tensor(-0.5996, device='cuda:0')]\n","tensor(-37.5465, device='cuda:0')\n","tensor(1.7818, device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kqjAR5aZKSv3"},"source":[""],"execution_count":null,"outputs":[]}]}