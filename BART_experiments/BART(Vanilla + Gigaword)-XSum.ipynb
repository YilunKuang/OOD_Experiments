{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BART(Vanilla + Gigaword)-XSum.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyN5mcKPhAZPs56xO9rzaGDd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10BPF1DyIgyS","executionInfo":{"status":"ok","timestamp":1624947393813,"user_tz":-480,"elapsed":525,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"eb5eb145-134e-4368-f5df-b1cf422d4fbc"},"source":["gpu_info_examine = !nvidia-smi\n","gpu_info_examine = '\\n'.join(gpu_info_examine)\n","if gpu_info_examine.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info_examine)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Jun 29 06:16:33 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P0    43W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Kky8CaTJZGD","executionInfo":{"status":"ok","timestamp":1624947394295,"user_tz":-480,"elapsed":5,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"1af3757b-36f4-49ef-fa9e-6355d88bce48"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Z79FsrpKDIJ","executionInfo":{"status":"ok","timestamp":1624947410324,"user_tz":-480,"elapsed":16032,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"f0358dcd-2e7d-48f1-e784-8c3b32944527"},"source":["!pip install transformers\n","!pip install datasets\n","!pip install torch\n","!pip install tqdm\n","!pip install numpy"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.8.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.6.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.5.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"10dG_tO_IN5u","executionInfo":{"status":"ok","timestamp":1624947411823,"user_tz":-480,"elapsed":1511,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}}},"source":["from transformers import AutoTokenizer, AutoModel, BartForConditionalGeneration, BartTokenizerFast\n","from datasets import load_dataset\n","import torch as torch\n","from tqdm import tqdm\n","from datasets import load_metric\n","import numpy as np"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"67EwXdPlOfOn","executionInfo":{"status":"ok","timestamp":1624947411829,"user_tz":-480,"elapsed":12,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"d275a9ca-7b6c-4871-afa2-a7de01d98e13"},"source":["torch.cuda.empty_cache()\n","torch.cuda.memory_summary(device=None, abbreviated=False)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Vq7w312Ic-2","executionInfo":{"status":"ok","timestamp":1624947419657,"user_tz":-480,"elapsed":7837,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"55404588-de6a-4674-9833-b1c0ebd2bea1"},"source":["model_checkpoint = 'a1noack/bart-large-gigaword' #'facebook/bart-large-cnn' #'facebook/bart-base' \n","tokenizer = BartTokenizerFast.from_pretrained(model_checkpoint)\n","model = BartForConditionalGeneration.from_pretrained(model_checkpoint, return_dict=True)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"uLkvuq5iPUqu","executionInfo":{"status":"ok","timestamp":1624947419660,"user_tz":-480,"elapsed":21,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"1cd10e27-d862-4171-abe7-89d33829a8e2"},"source":["torch.cuda.memory_summary(device=None, abbreviated=False)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BfVX8_OMJ3wF","executionInfo":{"status":"ok","timestamp":1624947420360,"user_tz":-480,"elapsed":719,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"9c93c3ae-5d09-4d23-aa68-b18d35e0b447"},"source":["# test = load_dataset(\"xsum\",split='test[0:5]')\n","# test = load_dataset(\"xsum\",split='test[5:10]')\n","# test = load_dataset(\"xsum\",split='test[10:15]')\n","test = load_dataset(\"xsum\",split='test[15:20]')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Using custom data configuration default\n","Reusing dataset xsum (/root/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAyGxfDcO74f","executionInfo":{"status":"ok","timestamp":1624947420361,"user_tz":-480,"elapsed":8,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"825de742-e0a8-43fa-c2f2-f30c835a1a31"},"source":["print(test)\n","print(model.config.max_length)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Dataset({\n","    features: ['document', 'id', 'summary'],\n","    num_rows: 5\n","})\n","32\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"uzzsJyOIO50G","executionInfo":{"status":"ok","timestamp":1624947420361,"user_tz":-480,"elapsed":5,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"463aa948-7d95-4bd5-a4c5-6e1681c085f5"},"source":["torch.cuda.memory_summary(device=None, abbreviated=False)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"FlN8ckklLW1n","executionInfo":{"status":"ok","timestamp":1624947422781,"user_tz":-480,"elapsed":2424,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}}},"source":["encodings =  tokenizer(test['document'], return_tensors='pt', padding=True, truncation=True, max_length=1024).to(device)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jBbXzI7MHH2","executionInfo":{"status":"ok","timestamp":1624947422782,"user_tz":-480,"elapsed":7,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"c800f49b-b099-4283-dd1a-0f9c03bd9cd5"},"source":["print(encodings['input_ids'].shape)\n","print(encodings['attention_mask'].shape)\n","encodings"],"execution_count":12,"outputs":[{"output_type":"stream","text":["torch.Size([5, 688])\n","torch.Size([5, 688])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[    0,   250,   471,  ...,  3266,    72,     2],\n","        [    0,  2409,   171,  ...,     1,     1,     1],\n","        [    0, 13365,   248,  ...,     1,     1,     1],\n","        [    0, 18801, 20083,  ...,     1,     1,     1],\n","        [    0,   133,  2491,  ...,     1,     1,     1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"nvu2bONLN5tU","executionInfo":{"status":"ok","timestamp":1624947422782,"user_tz":-480,"elapsed":5,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}}},"source":["# encodings['input_ids'][:5].shape\n","# encodings['input_ids'][10:].shape"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_EPUrgaJ5fa","executionInfo":{"status":"ok","timestamp":1624947423269,"user_tz":-480,"elapsed":491,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}}},"source":["model = model.to(device)\n","model.eval()\n","number_beams = 8"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hfITbbQqNbae","executionInfo":{"status":"ok","timestamp":1624947424368,"user_tz":-480,"elapsed":1100,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"567384c2-41cc-45ad-edfe-fc2b0ff6d3ca"},"source":["with torch.no_grad():\n","      result1 = model.generate(encodings['input_ids'],  num_beams=number_beams, return_dict_in_generate=True, max_length=model.config.max_length, output_scores=True, output_attentions=True)\n","    # result = model.generate(encodings['input_ids'],  num_beams=number_beams, return_dict_in_generate=True, max_length=model.config.max_length, output_scores=True, output_attentions=True)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n","To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n","  return torch.floor_divide(self, other)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H7hBLDjdKRnT","executionInfo":{"status":"ok","timestamp":1624947424369,"user_tz":-480,"elapsed":10,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"eef7d1cc-2d7e-470e-b80f-3143ffed5dfe"},"source":["all = []\n","log_sent = []\n","print(result1.sequences.shape)\n","print(\"CNN Dailymail vocab size: \", result1.scores[0].shape[1])\n","print(\"Input ids size\", encodings['input_ids'].shape)\n","for batch_num in range(0, result1.scores[0].shape[0], number_beams):\n","    # lls = torch.tensor(0, dtype=torch.float)\n","    # print(batch_num)\n","    max_score = torch.tensor(-1*1e6, dtype=torch.float).to(device)\n","    for beam_num in range(number_beams):\n","        print([torch.max(result1.scores[-1][batch_num+beam_num]), max_score])\n","        max_score = torch.max(torch.stack([torch.max(result1.scores[-1][batch_num+beam_num]), max_score]))\n","    log_sent.append(max_score)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["torch.Size([5, 17])\n","CNN Dailymail vocab size:  50264\n","Input ids size torch.Size([5, 688])\n","[tensor(-16.1679, device='cuda:0'), tensor(-1000000., device='cuda:0')]\n","[tensor(-17.4418, device='cuda:0'), tensor(-16.1679, device='cuda:0')]\n","[tensor(-18.0682, device='cuda:0'), tensor(-16.1679, device='cuda:0')]\n","[tensor(-18.4663, device='cuda:0'), tensor(-16.1679, device='cuda:0')]\n","[tensor(-19.0923, device='cuda:0'), tensor(-16.1679, device='cuda:0')]\n","[tensor(-19.5769, device='cuda:0'), tensor(-16.1679, device='cuda:0')]\n","[tensor(-19.7528, device='cuda:0'), tensor(-16.1679, device='cuda:0')]\n","[tensor(-19.9273, device='cuda:0'), tensor(-16.1679, device='cuda:0')]\n","[tensor(-22.3369, device='cuda:0'), tensor(-1000000., device='cuda:0')]\n","[tensor(-22.3611, device='cuda:0'), tensor(-22.3369, device='cuda:0')]\n","[tensor(-22.6953, device='cuda:0'), tensor(-22.3369, device='cuda:0')]\n","[tensor(-22.9048, device='cuda:0'), tensor(-22.3369, device='cuda:0')]\n","[tensor(-23.0213, device='cuda:0'), tensor(-22.3369, device='cuda:0')]\n","[tensor(-23.0226, device='cuda:0'), tensor(-22.3369, device='cuda:0')]\n","[tensor(-23.0539, device='cuda:0'), tensor(-22.3369, device='cuda:0')]\n","[tensor(-23.0878, device='cuda:0'), tensor(-22.3369, device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(-1000000., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(-21.2089, device='cuda:0'), tensor(-1000000., device='cuda:0')]\n","[tensor(-21.3373, device='cuda:0'), tensor(-21.2089, device='cuda:0')]\n","[tensor(-21.4259, device='cuda:0'), tensor(-21.2089, device='cuda:0')]\n","[tensor(-21.5355, device='cuda:0'), tensor(-21.2089, device='cuda:0')]\n","[tensor(-21.7888, device='cuda:0'), tensor(-21.2089, device='cuda:0')]\n","[tensor(-22.1262, device='cuda:0'), tensor(-21.2089, device='cuda:0')]\n","[tensor(-22.1634, device='cuda:0'), tensor(-21.2089, device='cuda:0')]\n","[tensor(-22.2780, device='cuda:0'), tensor(-21.2089, device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(-1000000., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n","[tensor(0., device='cuda:0'), tensor(0., device='cuda:0')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCpVGhegKSpc","executionInfo":{"status":"ok","timestamp":1624947424371,"user_tz":-480,"elapsed":10,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}},"outputId":"9af3fcb0-de59-4a5e-f652-61180e2bdea1"},"source":["print(log_sent)\n","print(torch.stack(log_sent).sum())\n","print(torch.exp((-1*(torch.stack(log_sent).sum()))/result1.sequences.shape[1]))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[tensor(-16.1679, device='cuda:0'), tensor(-22.3369, device='cuda:0'), tensor(0., device='cuda:0'), tensor(-21.2089, device='cuda:0'), tensor(0., device='cuda:0')]\n","tensor(-59.7136, device='cuda:0')\n","tensor(33.5342, device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kqjAR5aZKSv3","executionInfo":{"status":"ok","timestamp":1624947424372,"user_tz":-480,"elapsed":8,"user":{"displayName":"Yilun Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBOrEuCj1QH0V5Wt9RsEYKLHHr6eNAVGp9MZYO=s64","userId":"09309532567932469370"}}},"source":[""],"execution_count":17,"outputs":[]}]}